import re
import pandas as pd
import streamlit as st
from googleapiclient.discovery import build
from youtube_transcript_api import YouTubeTranscriptApi

# --- Page config ---
st.set_page_config(page_title="YouTube Channel Analyzer")

# --- Helpers ---
def extract_channel_id(url):
    url = url.split('?')[0]
    if 'channel/' in url:
        return url.split('channel/')[1]
    if 'user/' in url:
        name = url.split('user/')[1]
        res = youtube.channels().list(part='id', forUsername=name).execute()
        return res['items'][0]['id']
    if '/@' in url:
        handle = url.split('/@')[1]
        res = youtube.search().list(
            part='snippet', q=handle, type='channel', maxResults=1
        ).execute()
        return res['items'][0]['snippet']['channelId']
    st.error("URL í˜•ì‹ ì˜¤ë¥˜ (â†’ /channel/, /user/, ë˜ëŠ” @handle)")
    return None

@st.cache_data
def fetch_channel_videos(cid):
    # ì±„ë„ ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ì „ë¶€ ê°€ì ¸ì˜¤ê¸°
    pl = youtube.channels().list(part='contentDetails', id=cid).execute()
    upl = pl['items'][0]['contentDetails']['relatedPlaylists']['uploads']
    vids, token = [], None
    while True:
        r = youtube.playlistItems().list(
            part='snippet', playlistId=upl, maxResults=50, pageToken=token
        ).execute()
        vids += [i['snippet']['resourceId']['videoId'] for i in r['items']]
        token = r.get('nextPageToken')
        if not token:
            break
    return vids

@st.cache_data
def fetch_search_videos(q, country, count, vtype, period):
    # ìœ íŠœë¸Œ Search API
    params = dict(part='snippet', q=q, maxResults=count, type='video', regionCode=country)
    if vtype != 'ì „ì²´': params['videoDuration'] = 'short' if vtype=='ì‡¼ì¸ ' else 'long'
    if period!='ì „ì²´':
        # 1ê°œì›” ë‚´ â†’ 'month' etc
        mp = {'1ê°œì›”ë‚´':'month','3ê°œì›”ë‚´':'quarter','5ê°œì›” ì´ìƒ':'year'}[period]
        params['publishedAfter'] = pd.Timestamp.now() - pd.DateOffset(**{'months':1 if mp=='month' else 3 if mp=='quarter' else 6})
    res = youtube.search().list(**params).execute()
    return [i['id']['videoId'] for i in res['items']]

@st.cache_data
def fetch_video_details(vids):
    rows=[]
    for i in range(0, len(vids), 50):
        b=vids[i:i+50]
        r=youtube.videos().list(part='snippet,statistics', id=','.join(b)).execute()
        for it in r.get('items', []):
            rows.append({
                'id': it['id'],
                'title': it['snippet']['title'],
                'thumb': it['snippet']['thumbnails']['medium']['url'],
                'views': int(it['statistics'].get('viewCount',0)),
                'pub': it['snippet']['publishedAt'],
            })
    return pd.DataFrame(rows)

@st.cache_data
def fetch_sub_count(cid):
    r=youtube.channels().list(part='statistics', id=cid).execute()
    return int(r['items'][0]['statistics'].get('subscriberCount',0))

# --- UI ---
st.title("YouTube Channel Analyzer")

key = st.text_input("ğŸ”‘ YouTube API í‚¤", type="password")
use_search = st.checkbox("ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰ ëª¨ë“œ")
if use_search:
    kw = st.text_input("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ")
    country = st.selectbox("ê²€ìƒ‰ êµ­ê°€", ["KR","US","JP"], format_func=lambda x:{"KR":"í•œêµ­","US":"ë¯¸êµ­","JP":"ì¼ë³¸"}[x])
    cnt = st.selectbox("ê²€ìƒ‰ ê°œìˆ˜", [50,100,200,500])
    vtype= st.selectbox("ì˜ìƒ ìœ í˜•", ["ì „ì²´","ì‡¼ì¸ ","ë¡±í¼"])
    period=st.selectbox("ì—…ë¡œë“œ ê¸°ê°„", ["ì „ì²´","1ê°œì›”ë‚´","3ê°œì›”ë‚´","5ê°œì›” ì´ìƒ"])
else:
    url=st.text_input("ğŸ”— ì±„ë„ URL")

if key and ( (use_search and kw) or (not use_search and url) ):
    youtube = build('youtube','v3',developerKey=key)

    if use_search:
        vids = fetch_search_videos(kw, country, cnt, vtype, period)
        cid = None
    else:
        cid = extract_channel_id(url)
        vids = fetch_channel_videos(cid) if cid else []

    if vids:
        df = fetch_video_details(vids)
        avg = df['views'].mean()
        if cid:
            subs = fetch_sub_count(cid)
        else:
            subs = None

        # ë“±ê¸‰ ë° êµ¬ë…ì ì´ˆê³¼ ì˜ìƒ í‘œì‹œ
        df['grade'] = df['views'].apply(
            lambda v: '0' if v==0 else ('GREAT' if v>=1.5*avg else ('GOOD' if v>=avg else 'BAD'))
        )
        df['star'] = df['views'] >= 1.5*(subs if subs else avg)

        # ì •ë ¬
        order = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ì¡°íšŒìˆ˜â†“","ì¡°íšŒìˆ˜â†‘","ë“±ê¸‰","êµ¬ë…ììˆ˜â†“","êµ¬ë…ììˆ˜â†‘"])
        if order=="ì¡°íšŒìˆ˜â†“": df=df.sort_values('views',ascending=False)
        elif order=="ì¡°íšŒìˆ˜â†‘": df=df.sort_values('views',ascending=True)
        elif order=="ë“±ê¸‰":
            ordm={'GREAT':0,'GOOD':1,'BAD':2,'0':3}
            df['o']=df['grade'].map(ordm); df=df.sort_values('o').drop(columns='o')
        elif order=="êµ¬ë…ììˆ˜â†“": df=df.sort_values('star',ascending=False)
        else: df=df.sort_values('star',ascending=True)

        # í…Œì´ë¸” í‘œì‹œ
        for i,row in df.iterrows():
            c1,c2,c3=st.columns([1,4,1])
            c1.image(row['thumb'],width=120)
            txt = f"**{row['title']}**\nì¡°íšŒìˆ˜: {row['views']:,}"
            if subs:
                txt += f"\nêµ¬ë…ì: {subs:,}"
            txt += f"\nê²Œì‹œì¼: {row['pub'][:10]}"
            txt += f"\në“±ê¸‰: {'â­ '+row['grade'] if row['star'] else row['grade']}"
            c2.markdown(txt)
            if c3.button("ìŠ¤í¬ë¦½íŠ¸ ë‹¤ìš´",key=i):
                try:
                    t = YouTubeTranscriptApi.get_transcript(row['id'])
                    txt="\n".join([s['text'] for s in t])
                    st.download_button("TXTë¡œ ì €ì¥",txt,f"{row['id']}.txt","text/plain",key=f"dl{i}")
                except Exception as e:
                    st.error(f"ìŠ¤í¬ë¦½íŠ¸ ì˜¤ë¥˜: {e}")











